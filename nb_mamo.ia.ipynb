{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374bcad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import plotly.io as pio\n",
    "\n",
    "from helpers.datasetHelper import get_samples, split_data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from helpers.ploting import display_confusion_matrix_pink_variants\n",
    "from helpers.metaheuristics import run_pso_with_progress, run_ga_with_progress\n",
    "from models import MyXGboost\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "# Update the import to match the actual function name in hiper_params_search.py\n",
    "from hiper_params_search import get_best_xgboost\n",
    "\n",
    "# Set the default renderer to 'browser' to ensure plots open in the browser\n",
    "pio.renderers.default = 'browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976acb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path_combined = './datasets/GEO'\n",
    "GSE32396_HEALTHY_BRCA = get_samples(os.path.join(directory_path_combined, 'GSE32396-HEALTHYxBRCA.csv'))\n",
    "GSE41037_HEALTHY = get_samples(os.path.join(directory_path_combined, 'GSE41037_HEALTHY.csv'))\n",
    "GSE57285_HEALTHY_BRCA = get_samples(os.path.join(directory_path_combined, 'GSE57285-HEALTHYxBRCA.csv'))\n",
    "GSE58045_HEALTHY_UNK = get_samples(os.path.join(directory_path_combined, 'GSE58045-HEALTHY-UNK.csv'))\n",
    "GSE32396_HEALTHY_BRCA = get_samples(os.path.join(directory_path_combined, 'GSE32396-HEALTHYxBRCA.csv'))\n",
    "GSE58119_HEALTHY_PREBRCA = get_samples(os.path.join(directory_path_combined, 'GSE58119-HEALTHYxPRE-BRCA.csv'))\n",
    "\n",
    "datasets_list = [\n",
    "    GSE32396_HEALTHY_BRCA,\n",
    "    GSE41037_HEALTHY,\n",
    "    GSE57285_HEALTHY_BRCA,\n",
    "    GSE58045_HEALTHY_UNK,\n",
    "    GSE58119_HEALTHY_PREBRCA\n",
    "]\n",
    "\n",
    "tag_counts = {}\n",
    "all_instances = []\n",
    "\n",
    "for idx, dataset in enumerate(datasets_list):\n",
    "    # Ignore the first column for all rows except the header\n",
    "    tags = [row[1:] if i == 0 else row[-1] for i, row in enumerate(dataset)]\n",
    "    # For header row, skip (do not count as tag)\n",
    "    tags = [tag for tag in tags if not isinstance(tag, (np.ndarray, list))]\n",
    "    unique_tags, counts = np.unique(tags, return_counts=True)\n",
    "    print(f\"Dataset {idx+1}:\")\n",
    "    for tag, count in zip(unique_tags, counts):\n",
    "        print(f\"  {tag}: {count}\")\n",
    "        tag_counts[tag] = tag_counts.get(tag, 0) + count\n",
    "    print(f\"  Total: {len(tags)}\")\n",
    "    # Add all rows except header, and ignore first column\n",
    "    all_instances.extend([row[1:] for row in dataset[1:]])\n",
    "\n",
    "print(\"\\nConcatenated dataset:\")\n",
    "all_tags = [row[-1] for row in all_instances]\n",
    "unique_tags_all, counts_all = np.unique(all_tags, return_counts=True)\n",
    "for tag, count in zip(unique_tags_all, counts_all):\n",
    "    print(f\"  {tag}: {count}\")\n",
    "print(f\"  Total: {len(all_tags)}\")\n",
    "\n",
    "healthy_mt_cases, healthy_wt_cases, healthy_unk_cases, prebrca_cases, brca_mt_cases, brca_wt_cases = split_data(all_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b712d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def evaluate_model(patition_name, selector, X_val, y_val, label_encoder):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accuracy_vals, f1_vals, roc_auc_vals, sensitivity_vals, specificity_vals, precision_vals, kappa_vals = [], [], [], [], [], [], []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X_val, y_val):\n",
    "        X_fold, y_fold = X_val.iloc[test_idx], y_val[test_idx]\n",
    "        y_pred_fold = selector.predict(X_fold)\n",
    "        y_pred_proba_fold = selector.predict_proba(X_fold)\n",
    "\n",
    "        accuracy_vals.append(accuracy_score(y_fold, y_pred_fold))\n",
    "        f1_vals.append(f1_score(y_fold, y_pred_fold, average='weighted'))\n",
    "        sensitivity_vals.append(recall_score(y_fold, y_pred_fold, average='macro'))\n",
    "\n",
    "        specificities_fold = []\n",
    "        for class_idx in range(len(np.unique(y_val))):\n",
    "            true_neg = np.sum((y_fold != class_idx) & (y_pred_fold != class_idx))\n",
    "            total_neg = np.sum(y_fold != class_idx)\n",
    "            specificities_fold.append(true_neg / total_neg if total_neg > 0 else 0)\n",
    "        specificity_vals.append(np.mean(specificities_fold))\n",
    "        precision_vals.append(precision_score(y_fold, y_pred_fold, average='weighted'))\n",
    "\n",
    "        if y_pred_proba_fold.shape[1] == 2:\n",
    "            roc_auc_vals.append(roc_auc_score(y_fold, y_pred_proba_fold[:, 1]))\n",
    "        else:\n",
    "            roc_auc_vals.append(roc_auc_score(y_fold, y_pred_proba_fold, multi_class='ovr'))\n",
    "\n",
    "        kappa_vals.append(cohen_kappa_score(y_fold, y_pred_fold))\n",
    "\n",
    "    accuracy_val = np.mean(accuracy_vals)\n",
    "    f1_val = np.mean(f1_vals)\n",
    "    roc_auc_val = np.mean(roc_auc_vals)\n",
    "    sensitivity_val = np.mean(sensitivity_vals)\n",
    "    specificity_val = np.mean(specificity_vals)\n",
    "    precision_val = np.mean(precision_vals)\n",
    "    kappa_val = np.mean(kappa_vals)\n",
    "\n",
    "    print(f\"{patition_name} Accuracy (cv = 5): {accuracy_val:.4f}\")\n",
    "    print(f\"{patition_name} F1 Score (cv = 5): {f1_val:.4f}\")\n",
    "    print(f\"{patition_name} ROC AUC (cv = 5): {roc_auc_val:.4f}\")\n",
    "    print(f\"{patition_name} Sensitivity (cv = 5) : {sensitivity_val:.4f}\")\n",
    "    print(f\"{patition_name} Specificity (cv = 5): {specificity_val:.4f}\")\n",
    "    print(f\"{patition_name} Precision (cv = 5): {precision_val:.4f}\")\n",
    "    print(f\"{patition_name} Kappa index (cv = 5): {kappa_val:.4f}\")\n",
    "\n",
    "    with open(\"evaluation_results.txt\", \"w\") as f:\n",
    "        f.write(f\"{patition_name} Accuracy (cv = 5): {accuracy_val:.4f}\\n\")\n",
    "        f.write(f\"{patition_name} F1 Score (cv = 5): {f1_val:.4f}\\n\")\n",
    "        f.write(f\"{patition_name} ROC AUC (cv = 5): {roc_auc_val:.4f}\\n\")\n",
    "        f.write(f\"{patition_name} Sensitivity (cv = 5) : {sensitivity_val:.4f}\\n\")\n",
    "        f.write(f\"{patition_name} Specificity (cv = 5): {specificity_val:.4f}\\n\")\n",
    "        f.write(f\"{patition_name} Precision (cv = 5): {precision_val:.4f}\\n\")\n",
    "        f.write(f\"{patition_name} Kappa index (cv = 5): {kappa_val:.4f}\\n\")\n",
    "\n",
    "    display_confusion_matrix_pink_variants(selector, X_val, y_val, label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e1952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframes(X, Y):\n",
    "    n_features = X.shape[1]\n",
    "    print(f\"Loaded dataset with {n_features} features and {len(Y)} samples\")\n",
    "\n",
    "    # Use DecisionTreeClassifier as the estimator\n",
    "    estimator = MyXGboost.DecisionTreeMultiClass()\n",
    "\n",
    "    # Run PSO\n",
    "    best_weights, best_fitness, progress, X_selected = run_pso_with_progress(\n",
    "        X, Y, estimator, n_features,\n",
    "        swarmsize=30,\n",
    "        maxiter=10,\n",
    "        threshold=0.7\n",
    "    )\n",
    "\n",
    "    X_selected_pso = X.iloc[:, X_selected]\n",
    "\n",
    "    best_weights_ga, best_fitness_ga, progress_ga, X_selected_proc = run_ga_with_progress(\n",
    "    X, Y, estimator, X.shape[1], \n",
    "    pop_size=25, n_generations=10, threshold=0.8\n",
    "    )\n",
    "\n",
    "    X_selected_ga = X.iloc[:, X_selected_proc]\n",
    "\n",
    "    # Use LabelEncoder to encode the target classes\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(Y)\n",
    "    Y_encoded = label_encoder.transform(Y)\n",
    "    print(\"Label indices and names:\")\n",
    "    for idx, name in enumerate(label_encoder.classes_):\n",
    "        print(f\"{idx}: {name}\")\n",
    "\n",
    "    print(f\"Encoded target classes: {label_encoder.classes_}\")\n",
    "\n",
    "    # 1) evaluate with all features\n",
    "    X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(\n",
    "        X, Y_encoded, test_size=0.3, random_state=42\n",
    "    )    \n",
    "    # Split X_test_all and y_test_all into validation and test sets (15% each)\n",
    "    X_val_nfs, X_test_nfs, y_val_nfs, y_test_nfs = train_test_split(\n",
    "        X_test_all, y_test_all, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    # 2) evaluate with selected features\n",
    "    X_train_ga, X_test_ga, y_train_ga, y_test_ga = train_test_split(\n",
    "        X_selected_ga, Y_encoded, test_size=0.3, random_state=42\n",
    "    )\n",
    "    # Split X_test_all and y_test_all into validation and test sets (15% each)\n",
    "    X_val_ga, X_test_ga, y_val_ga, y_test_ga = train_test_split(\n",
    "        X_test_ga, y_test_ga, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    # 3) evaluate with PSO selected features\n",
    "    X_train_pso, X_test_pso, y_train_pso, y_test_pso = train_test_split(\n",
    "        X_selected_pso, Y_encoded, test_size=0.3, random_state=42\n",
    "    )\n",
    "    # Split X_test_all and y_test_all into validation and test sets (15% each)\n",
    "    X_val_pso, X_test_pso, y_val_pso, y_test_pso = train_test_split(\n",
    "        X_test_pso, y_test_pso, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    # Apply SMOTE to balance the training instances - ALL\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=10)\n",
    "    X_train_nfs, y_train_nfs = smote.fit_resample(X_train_nfs, y_train_nfs)\n",
    "\n",
    "    # Apply SMOTE to balance the training instances - GA\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=10)\n",
    "    X_train_ga, y_train_ga = smote.fit_resample(X_train_ga, y_train_ga)\n",
    "\n",
    "    # Apply SMOTE to balance the training instances - PSO\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=10)\n",
    "    X_train_pso, y_train_pso = smote.fit_resample(X_train_pso, y_train_pso)\n",
    "\n",
    "    return [('GA', X_train_ga, X_test_ga, X_val_ga, y_train_ga, y_test_ga, y_val_ga), \n",
    "                   ('PSO', X_train_pso, X_test_pso, X_val_pso, y_train_pso, y_test_pso, y_val_pso),\n",
    "                   ('ALL', X_train_nfs, X_test_nfs, X_val_nfs, y_train_nfs, y_test_nfs, y_val_nfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fcf7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_mt_cases = pd.DataFrame(healthy_mt_cases)\n",
    "healthy_wt_cases = pd.DataFrame(healthy_wt_cases)\n",
    "healthy_unk_cases = pd.DataFrame(healthy_unk_cases)\n",
    "\n",
    "prebrca_cases = pd.DataFrame(prebrca_cases)\n",
    "\n",
    "brca_mt_cases = pd.DataFrame(brca_mt_cases)\n",
    "brca_wt_cases = pd.DataFrame(brca_wt_cases)\n",
    "\n",
    "healthy_consolidated_cases = pd.concat([healthy_mt_cases, healthy_wt_cases, healthy_unk_cases], ignore_index=True)\n",
    "healthy_consolidated_cases['Tag'] = 'HEALTHY'\n",
    "brca_consolidated_cases = pd.concat([brca_mt_cases, brca_wt_cases], ignore_index=True)\n",
    "brca_consolidated_cases['Tag'] = 'BRCA'\n",
    "\n",
    "\n",
    "healthy_mt_cases['Tag'] = 'HEALTHY-MT'\n",
    "healthy_wt_cases['Tag'] = 'HEALTHY-WT'\n",
    "healthy_unk_cases['Tag'] = 'HEALTHY-UNK'\n",
    "\n",
    "prebrca_cases['Tag'] = 'PRE-BRCA'\n",
    "\n",
    "brca_mt_cases['Tag'] = 'BRCA-MUT'\n",
    "brca_wt_cases['Tag'] = 'BRCA-WT'\n",
    "\n",
    "brca_consolidated_cases['Tag'] = 'BRCA'\n",
    "\n",
    "print(f\"Healthy MT cases shape: {healthy_mt_cases.shape}\")\n",
    "print(f\"Healthy WT cases shape: {healthy_wt_cases.shape}\")\n",
    "print(f\"Healthy consolidated cases shape: {healthy_consolidated_cases.shape}\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(f\"PRE-BRCA cases shape: {prebrca_cases.shape}\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(f\"BRCA MT cases shape: {brca_mt_cases.shape}\")\n",
    "print(f\"BRCA WT cases shape: {brca_wt_cases.shape}\")    \n",
    "print(f\"BRCA consolidated cases shape: {brca_consolidated_cases.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ced203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer = pd.concat([healthy_unk_cases, brca_consolidated_cases], ignore_index=True) #blood samples\n",
    "X = df_cancer.iloc[:, :-1].apply(pd.to_numeric, errors='coerce')\n",
    "Y = df_cancer.iloc[:, -1]\n",
    "\n",
    "# Fill missing values with the lowest value of its cpg site\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(Y)\n",
    "Y_encoded = label_encoder.transform(Y)\n",
    "\n",
    "print(\"Label indices and names:\")\n",
    "for idx, name in enumerate(label_encoder.classes_):\n",
    "    print(f\"{idx}: {name}\")\n",
    "\n",
    "X_train, X_test_all, y_train_all, y_test_all = train_test_split(\n",
    "    X, Y_encoded, test_size=0.40, random_state=42\n",
    ")\n",
    "\n",
    "# Split X_test_all and y_test_all into validation and test sets (15% each)\n",
    "X_val_nfs, X_test, y_val_nfs, y_test_nfs = train_test_split(\n",
    "    X_test_all, y_test_all, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Better approach - use training statistics only\n",
    "X_val_nfs = X_val_nfs.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "X_test = X_test.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "X_train = X_train.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "\n",
    "print(\"Class distribution in full dataset:\")\n",
    "print(pd.Series(Y_encoded).value_counts().sort_index(), label_encoder.classes_)\n",
    "\n",
    "print(\"Class distribution in training set (nfs):\")\n",
    "print(pd.Series(y_train_all).value_counts().sort_index(), label_encoder.classes_)\n",
    "\n",
    "print(\"Class distribution in test set:\")\n",
    "print(pd.Series(y_test_nfs).value_counts().sort_index(), label_encoder.classes_)\n",
    "\n",
    "print(\"Class distribution in validation set:\")\n",
    "print(pd.Series(y_val_nfs).value_counts().sort_index(), label_encoder.classes_)\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=5)\n",
    "X_train, y_train_all = smote.fit_resample(X_train, y_train_all)\n",
    "\n",
    "selector = MyXGboost.XGBoostBinary()[0].fit(X_train, y_train_all)\n",
    "# Evaluate the model on the validation set\n",
    "evaluate_model(\"Validation\", selector, X_val_nfs, y_val_nfs, label_encoder)\n",
    "evaluate_model(\"Test\", selector, X_test, y_test_nfs, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_multiclass = [\n",
    "    {\n",
    "        'Name': 'Random Forest',\n",
    "        'Model': MyXGboost.RandomForest300()\n",
    "    },\n",
    "    {\n",
    "        'Name': 'XGBoost',\n",
    "        'Model': MyXGboost.XGBoostMultiClass()\n",
    "    },\n",
    "    {\n",
    "        'Name': 'Light GBM',\n",
    "        'Model': MyXGboost.LightGBMMulticlass()\n",
    "    },\n",
    "    {\n",
    "        'Name': 'Gradient Boosting',\n",
    "        'Model': MyXGboost.GradientBoosting()\n",
    "    },\n",
    "    {\n",
    "        'Name': 'Ada Boost',\n",
    "        'Model': MyXGboost.AdaBoostMultiClass()\n",
    "    }\n",
    "]\n",
    "\n",
    "models_binary = [\n",
    "    {\n",
    "        'Name': 'Random Forest',\n",
    "        'Model': MyXGboost.RandomForest300()\n",
    "    },\n",
    "    {\n",
    "        'Name': 'XGBoost',\n",
    "        'Model': MyXGboost.XGBoostBinary()\n",
    "    },\n",
    "    {\n",
    "        'Name': 'Light GBM',\n",
    "        'Model': MyXGboost.LightGBMBinary()\n",
    "    },\n",
    "    {\n",
    "        'Name': 'Gradient Boosting',\n",
    "        'Model': MyXGboost.GradientBoosting()\n",
    "    },\n",
    "    {\n",
    "        'Name': 'Ada Boost',\n",
    "        'Model': MyXGboost.AdaBoostBinary()\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e746129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pso(df_cancer):\n",
    "    X = df_cancer.iloc[:, :-1].apply(pd.to_numeric, errors='coerce')\n",
    "    Y = df_cancer.iloc[:, -1]\n",
    "\n",
    "    # Fill missing values with the lowest value of its cpg site\n",
    "    X = X.apply(lambda col: col.fillna(col.min()), axis=0)\n",
    "\n",
    "    n_features = X.shape[1]\n",
    "    print(f\"Loaded dataset with {n_features} features and {len(Y)} samples\")\n",
    "\n",
    "    # Use DecisionTreeClassifier as the estimator\n",
    "    estimator = MyXGboost.DecisionTreeMultiClass()\n",
    "\n",
    "    # Run PSO\n",
    "    best_weights, best_fitness, progress, X_selected = run_pso_with_progress(\n",
    "        X, Y, estimator, n_features,\n",
    "        swarmsize=30,\n",
    "        maxiter=10,\n",
    "        threshold=0.8\n",
    "    )\n",
    "\n",
    "\n",
    "    X_selected_pso = X.iloc[:, X_selected]\n",
    "\n",
    "    print(f\"Done PSO â†’ best fitness = {best_fitness:.4f}\")\n",
    "\n",
    "    return X_selected_pso\n",
    "\n",
    "def process_ga(df_cancer):\n",
    "    X = df_cancer.iloc[:, :-1].apply(pd.to_numeric, errors='coerce')\n",
    "    Y = df_cancer.iloc[:, -1]\n",
    "\n",
    "    # Fill missing values with the lowest value of its cpg site\n",
    "    X = X.apply(lambda col: col.fillna(col.min()), axis=0)\n",
    "\n",
    "    n_features = X.shape[1]\n",
    "    print(f\"Loaded dataset with {n_features} features and {len(Y)} samples\")\n",
    "\n",
    "    # Use DecisionTreeClassifier as the estimator\n",
    "    estimator = MyXGboost.DecisionTreeMultiClass()\n",
    "\n",
    "    best_weights_ga, best_fitness_ga, progress_ga, X_selected_proc = run_ga_with_progress(\n",
    "        X, Y, estimator, X.shape[1], \n",
    "        pop_size=30, n_generations=5, threshold=0.8\n",
    "    )\n",
    "\n",
    "\n",
    "    X_selected_ga = X.iloc[:, X_selected_proc]\n",
    "\n",
    "    return X_selected_ga\n",
    "\n",
    "datasets = {\n",
    "    'Healthy vs BRCA': [healthy_unk_cases, brca_consolidated_cases],\n",
    "    'Healthy vs PRE-BRCA VS BRCA': [healthy_unk_cases, prebrca_cases, brca_consolidated_cases],\n",
    "    'Healthy vs PRE-BRCA': [healthy_unk_cases, prebrca_cases],\n",
    "    'PRE-BRCA vs BRCA': [prebrca_cases, brca_consolidated_cases],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors_pso = []\n",
    "\n",
    "for key in datasets:\n",
    "    X_selected_pso = process_pso(pd.concat(datasets[key], ignore_index=True))\n",
    "    X = X_selected_pso\n",
    "\n",
    "    Y = pd.concat(datasets[key], ignore_index=True).iloc[:, -1]\n",
    "    label_encoder = LabelEncoder()\n",
    "    Y_encoded = label_encoder.fit_transform(Y)\n",
    "\n",
    "    models = models_binary if len(np.unique(Y)) == 2 else models_multiclass\n",
    "    total_features_selcted = len(X_selected_pso)\n",
    "    print(f\"Total features selected by PSO: {total_features_selcted}\")\n",
    "\n",
    "    for model_info in models:\n",
    "        print(f\"Training model: {model_info['Name']}\")        \n",
    "\n",
    "        # Split data        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, Y_encoded, test_size=0.40, random_state=42\n",
    "        )\n",
    "\n",
    "        # Split X_test and y_test into validation and test sets (15% each)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_test, y_test, test_size=0.5, random_state=42\n",
    "        )\n",
    "\n",
    "        # Better approach - use training statistics only\n",
    "        X_val = X_val.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "        X_test = X_test.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "        X_train = X_train.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=5)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        model = model_info['Model'][0] if isinstance(model_info['Model'], (list, tuple)) else model_info['Model']\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        info = f\"{model_info['Name']} - {key} - VALIDATION\"\n",
    "        evaluate_model(info, model, X_test, y_test, label_encoder)\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        info = f\"{model_info['Name']} - {key} - TEST\"\n",
    "        evaluate_model(info, model, X_test, y_test, label_encoder)\n",
    "\n",
    "        selectors_pso.append({\n",
    "            name: info,\n",
    "            selector: model\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors_ga = []\n",
    "\n",
    "for key in datasets:\n",
    "    X_selected_ga = process_ga(pd.concat(datasets[key], ignore_index=True))\n",
    "    X = X_selected_ga\n",
    "\n",
    "    Y = pd.concat(datasets[key], ignore_index=True).iloc[:, -1]\n",
    "    label_encoder = LabelEncoder()\n",
    "    Y_encoded = label_encoder.fit_transform(Y)\n",
    "\n",
    "    models = models_binary if len(np.unique(Y)) == 2 else models_multiclass\n",
    "    total_features_selcted = len(X_selected_ga)\n",
    "    print(f\"Total features selected by GA: {total_features_selcted}\")\n",
    "\n",
    "    for model_info in models:\n",
    "        print(f\"Training model: {model_info['Name']}\")        \n",
    "\n",
    "        # Split data        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, Y_encoded, test_size=0.40, random_state=42\n",
    "        )\n",
    "\n",
    "        # Split X_test and y_test into validation and test sets (15% each)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_test, y_test, test_size=0.5, random_state=42\n",
    "        )\n",
    "\n",
    "        # Better approach - use training statistics only\n",
    "        X_val = X_val.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "        X_test = X_test.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "        X_train = X_train.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=5)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        model = model_info['Model'][0] if isinstance(model_info['Model'], (list, tuple)) else model_info['Model']\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        info = f\"{model_info['Name']} - {key} - VALIDATION\"\n",
    "        evaluate_model(info, model, X_test, y_test, label_encoder)\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        info = f\"{model_info['Name']} - {key} - TEST\"\n",
    "        evaluate_model(info, model, X_test, y_test, label_encoder)\n",
    "\n",
    "        selectors_ga.append({\n",
    "            name: info,\n",
    "            selector: model\n",
    "            })\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a7f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
