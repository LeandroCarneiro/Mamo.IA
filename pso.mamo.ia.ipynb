{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from helpers.datasetHelper import get_samples, split_healthy_data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from helpers.metaheuristics import run_pso_with_progress, run_ga_with_progress\n",
    "from models import MyXGboost\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory_path = './datasets'\n",
    "data_health = get_samples(os.path.join(directory_path, 'DT.Healthy.csv'))\n",
    "\n",
    "# Load the PAN-CANCER-TRANSPOSED.csv data\n",
    "healthy_cases, prebrca_cases, cancer_cases = split_healthy_data(data_health)\n",
    "\n",
    "# Combine the data into a single dataframe\n",
    "# Tag each list of cases\n",
    "healthy_cases = pd.DataFrame(healthy_cases)\n",
    "healthy_cases['Tag'] = 'HEALTHY'\n",
    "prebrca_cases = pd.DataFrame(prebrca_cases)\n",
    "prebrca_cases['Tag'] = 'PRE-BRCA'\n",
    "cancer_cases = pd.DataFrame(cancer_cases)\n",
    "cancer_cases['Tag'] = 'BRCA'\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "df_cancer = pd.concat([healthy_cases, prebrca_cases, cancer_cases], ignore_index=True) #blood samples\n",
    "X = df_cancer.iloc[:, :-1].apply(pd.to_numeric, errors='coerce')\n",
    "Y = df_cancer.iloc[:, -1]\n",
    "\n",
    "feature_names = np.array(data_health[0][:-1])\n",
    "\n",
    "# Fill missing values with the lowest value of its cpg site\n",
    "X = X.apply(lambda col: col.fillna(col.min()), axis=0)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "print(f\"Loaded dataset with {n_features} features and {len(Y)} samples\")\n",
    "\n",
    "# Use DecisionTreeClassifier as the estimator\n",
    "estimator = MyXGboost.DecisionTreeMultiClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PSO\n",
    "best_weights, best_fitness, progress, X_selected = run_pso_with_progress(\n",
    "    X, Y, estimator, n_features,\n",
    "    swarmsize=1000,\n",
    "    maxiter=100,\n",
    "    threshold=0.7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_selected_pso = X.iloc[:, X_selected]\n",
    "selected_feature_names = feature_names[X_selected]\n",
    "\n",
    "print(f\"Done PSO → best fitness = {best_fitness:.4f}\")\n",
    "print(f\"Number of selected features: {len(selected_feature_names)}\")\n",
    "print(f\"Selected feature indices: {selected_feature_names[:10]}...\")  # Show first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4857c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_weights_ga, best_fitness_ga, progress_ga, X_selected_proc = run_ga_with_progress(\n",
    "    X, Y, estimator, X.shape[1], \n",
    "    pop_size=5, n_generations=40, threshold=0.9\n",
    ")\n",
    "\n",
    "# Convert best_weights_ga to numpy array before comparison\n",
    "X_selected_ga = X.iloc[:, X_selected_proc]\n",
    "selected_feature_names_ga = feature_names[X_selected_proc]\n",
    "\n",
    "print(f\"Done GA → best fitness = {best_fitness_ga:.4f}\")\n",
    "print(f\"Number of selected features: {len(selected_feature_names_ga)}\")\n",
    "print(f\"Selected feature indices: {selected_feature_names_ga[:10]}...\")  # Show first 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f39ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use LabelEncoder to encode the target classes\n",
    "label_encoder = LabelEncoder()\n",
    "# Define the order: Healthy -> Pre-BRCA -> BRCA\n",
    "ordered_labels = ['HEALTHY', 'PRE-BRCA', 'BRCA']\n",
    "label_encoder.fit(ordered_labels)\n",
    "Y_encoded = label_encoder.transform(Y)\n",
    "\n",
    "print(f\"Encoded target classes: {label_encoder.classes_}\")\n",
    "\n",
    "# 1) evaluate with all features\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(\n",
    "    X, Y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "# 2) evaluate with selected features\n",
    "X_train_ga, X_test_ga, y_train_ga, y_test_ga = train_test_split(\n",
    "    X_selected_ga, Y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "# 3) evaluate with PSO selected features\n",
    "X_train_pso, X_test_pso, y_train_pso, y_test_pso = train_test_split(\n",
    "    X_selected_pso, Y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Apply SMOTE to balance the training instances - ALL\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=5)\n",
    "X_train_all, y_train_all = smote.fit_resample(X_train_all, y_train_all)\n",
    "\n",
    "# Apply SMOTE to balance the training instances - GA\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=5)\n",
    "X_train_ga, y_train_ga = smote.fit_resample(X_train_ga, y_train_ga)\n",
    "\n",
    "# Apply SMOTE to balance the training instances - PSO\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=5)\n",
    "X_train_pso, y_train_pso = smote.fit_resample(X_train_pso, y_train_pso)\n",
    "\n",
    "modes = [\n",
    "    {\n",
    "        'Name': 'XGBoost',\n",
    "        'Model': MyXGboost.XGBoostMultiClass()\n",
    "    },\n",
    "    {\n",
    "        'Name': 'LightGBM',\n",
    "        'Model': MyXGboost.LightGBMMulticlass()\n",
    "    },\n",
    "    {\n",
    "        'Name': 'RandomForest300',\n",
    "        'Model': MyXGboost.RandomForest300()\n",
    "    },\n",
    "    {\n",
    "        'Name': 'GradientBoosting',\n",
    "        'Model': MyXGboost.GradientBoosting()\n",
    "    }\n",
    "]\n",
    "\n",
    "# Print dimensions of different training datasets\n",
    "print(\"Training data dimensions:\")\n",
    "print(f\"Original data (X_train_all): {X_train_all.shape}\")\n",
    "print(f\"GA selected features (X_train_ga): {X_train_ga.shape}\")\n",
    "print(f\"PSO selected features (X_train_pso): {X_train_pso.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "def display_confusion_matrix(estimator, X_test, y_test):\n",
    "    # Get predictions\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    \n",
    "    # Create confusion matrix (normalized by true labels)\n",
    "    cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "    \n",
    "    # Convert to percentage\n",
    "    cm = cm * 100\n",
    "    \n",
    "    # Create a dataframe for plotting\n",
    "    classes = label_encoder.classes_\n",
    "    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    \n",
    "    fig = px.imshow(\n",
    "        df_cm,\n",
    "        text_auto='.1f',\n",
    "        color_continuous_scale=[\n",
    "            \"#f8bbd0\",  # light pink\n",
    "            \"#f06292\",  # medium pink\n",
    "            \"#ad1457\"   # dark pink\n",
    "        ],\n",
    "        aspect=\"auto\",\n",
    "        labels=dict(x=\"Predicted Label\", y=\"True Label\", color=\"Percentage\"),\n",
    "        title=\"Confusion Matrix (Pink Variants)\"\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Optional: Return the figure for further customization or saving\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for feature_set in [('GA', X_train_ga, X_test_ga, y_train_ga, y_test_ga), \n",
    "                   ('PSO', X_train_pso, X_test_pso, y_train_pso, y_test_pso),\n",
    "                   ('All', X_train_all, X_test_all, y_train_all, y_test_all)]:\n",
    "    \n",
    "    method, X_train, X_test, y_train, y_test = feature_set\n",
    "    print(f\"\\n=== Results for {method} selected features ===\")\n",
    "    \n",
    "    for m in modes:\n",
    "        # Split training data into train and validation sets for early stopping\n",
    "        X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=42\n",
    "        )   \n",
    "\n",
    "        selector = m['Model'][0].fit(X_train_split, y_train_split)\n",
    "        # Use the best model from grid search\n",
    "        # selector = get_best[0]\n",
    "    \n",
    "        # Evaluate the model\n",
    "        y_pred = selector.predict(X_test)\n",
    "        y_pred_proba = selector.predict_proba(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        # Handle binary and multiclass cases for ROC AUC\n",
    "        if y_pred_proba.shape[1] == 2:\n",
    "            roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "\n",
    "        print(f\"\\nModel: {m['Name']}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "        # Compute Kappa index\n",
    "        kappa = cohen_kappa_score(y_test, y_pred)\n",
    "        print(f\"Kappa index: {kappa:.4f}\")\n",
    "\n",
    "        # Confusion matrix\n",
    "        display_confusion_matrix(selector, X_test, y_test)\n",
    "        \n",
    "        # Feature importance (if available)\n",
    "        if hasattr(selector, 'feature_importances_'):\n",
    "            importances = selector.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1][:20]\n",
    "            print(\"\\nTop 20 important features:\")\n",
    "            feature_names = selected_feature_names_ga if method == 'GA' else selected_feature_names\n",
    "            # Choose correct feature names based on method\n",
    "            if method == 'GA':\n",
    "                feature_names_to_use = selected_feature_names_ga\n",
    "            elif method == 'PSO':\n",
    "                feature_names_to_use = selected_feature_names\n",
    "            else:\n",
    "                feature_names_to_use = feature_names\n",
    "\n",
    "            for rank, idx in enumerate(indices, 1):\n",
    "                # Only print if idx is within bounds\n",
    "                if idx < len(feature_names_to_use):\n",
    "                    print(f\"{rank}. {feature_names_to_use[idx]}: {importances[idx]:.4f}\")\n",
    "                else:\n",
    "                    print(f\"{rank}. [Index {idx} out of bounds]\")\n",
    "        else:\n",
    "            print(\"\\nThis model does not provide feature importances.\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "# ('GA', X_train_ga, X_test_ga, y_train_ga, y_test_ga)\n",
    "# ('PSO', X_train_pso, X_test_pso, y_train_pso, y_test_pso)\n",
    "# ('All', X_train_all, X_test_all, y_train_all, y_test_all)\n",
    "\n",
    "X_train_split = X_train_all\n",
    "X_test = X_test_all\n",
    "y_train_split = y_train_all\n",
    "\n",
    "selector = MyXGboost.LightGBMMulticlass()[0].fit(X_train_split, y_train_split)\n",
    "# Evaluate the model\n",
    "y_pred = selector.predict(X_test)\n",
    "y_pred_proba = selector.predict_proba(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "# Handle binary and multiclass cases for ROC AUC\n",
    "if y_pred_proba.shape[1] == 2:\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "else:\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "\n",
    "print(f\"\\nModel: {selector.__class__.__name__}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Compute Kappa index\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(f\"Kappa index: {kappa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ee7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Print class distribution for train and test sets (GA-selected features as example)\n",
    "\n",
    "def print_class_distribution(y, label_encoder, dataset_name):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"\\nClass distribution in {dataset_name}:\")\n",
    "    for label, count in zip(label_encoder.inverse_transform(unique), counts):\n",
    "        print(f\"  {label}: {count}\")\n",
    "\n",
    "print_class_distribution(Y_encoded, label_encoder, \"Train\")\n",
    "print_class_distribution(y_test_all, label_encoder, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "\n",
    "n_classes = y_pred_proba.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc_dict = dict()\n",
    "roc_data = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_proba[:, i], pos_label=i)\n",
    "    roc_auc_dict[i] = auc(fpr[i], tpr[i])\n",
    "    roc_data.append(pd.DataFrame({\n",
    "        \"fpr\": fpr[i],\n",
    "        \"tpr\": tpr[i],\n",
    "        \"class\": [label_encoder.classes_[i]] * len(fpr[i]),\n",
    "        \"auc\": [roc_auc_dict[i]] * len(fpr[i])\n",
    "    }))\n",
    "\n",
    "roc_df = pd.concat(roc_data, ignore_index=True)\n",
    "\n",
    "fig = px.line(\n",
    "    roc_df,\n",
    "    x=\"fpr\",\n",
    "    y=\"tpr\",\n",
    "    color=\"class\",\n",
    "    line_dash=\"class\",\n",
    "    title=\"ROC Curve (One-vs-Rest, Plotly)\",\n",
    "    labels={\"fpr\": \"False Positive Rate\", \"tpr\": \"True Positive Rate\"},\n",
    "    hover_data=[\"auc\"]\n",
    ")\n",
    "fig.update_traces(mode='lines+markers', line_shape='spline')\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=0, y0=0, x1=1, y1=1,\n",
    "    line=dict(color=\"black\", dash=\"dash\"),\n",
    "    name=\"Random\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"Class\",\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
